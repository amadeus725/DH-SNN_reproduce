#!/usr/bin/env python3
"""
DH-SNN SSCï¼ˆè„‰å†²è¯­éŸ³å‘½ä»¤ï¼‰å®éªŒ
==================================

åŸºäºSpikingJellyæ¡†æ¶çš„DH-SNN vs æ™®é€šSNNå¯¹æ¯”å®éªŒ
ä½¿ç”¨SSCæ•°æ®é›†è¿›è¡Œè¯­éŸ³å‘½ä»¤è¯†åˆ«ä»»åŠ¡

"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import tables
import time
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent.parent.parent
sys.path.append(str(current_dir))

# SpikingJellyå¯¼å…¥
from spikingjelly.activation_based import neuron, functional, layer, surrogate

from dh_snn.utils import setup_seed

print("ğŸ¯ DH-SNN SSCè„‰å†²è¯­éŸ³å‘½ä»¤è¯†åˆ«å®éªŒ")
print("="*60)

# å®éªŒå‚æ•°
torch.manual_seed(42)
BATCH_SIZE = 100
LEARNING_RATE = 1e-2
NUM_EPOCHS = 100
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ä¸´æ—¶æ•°æ®è·¯å¾„
TEMP_DIR = "/tmp/ssc_data"

# ==================== æ•°æ®å¤„ç† ====================

def binary_image_readout_fast(times, units, dt=1e-3):
    """
    ä¼˜åŒ–çš„äºŒè¿›åˆ¶å›¾åƒè¯»å–å‡½æ•°
    å°†è„‰å†²æ—¶é—´å’Œç¥ç»å…ƒç´¢å¼•è½¬æ¢ä¸ºå¯†é›†çš„è„‰å†²å¼ é‡
    
    å‚æ•°:
        times: è„‰å†²æ—¶é—´æ•°ç»„
        units: ç¥ç»å…ƒå•å…ƒç´¢å¼•æ•°ç»„ 
        dt: æ—¶é—´æ­¥é•¿
    
    è¿”å›:
        img: å½¢çŠ¶ä¸º[æ—¶é—´æ­¥, ç¥ç»å…ƒæ•°]çš„è„‰å†²å¼ é‡
    """
    N = int(1/dt)  # æ€»æ—¶é—´æ­¥æ•°
    img = np.zeros((N, 700), dtype=np.float32)  # SSCæœ‰700ä¸ªç¥ç»å…ƒ
    
    # å‘é‡åŒ–å¤„ç†ä»¥æé«˜æ•ˆç‡
    time_bins = (times / dt).astype(int)
    valid_mask = (time_bins < N) & (units > 0) & (units <= 700)
    
    if np.any(valid_mask):
        valid_times = time_bins[valid_mask]
        valid_units = units[valid_mask]
        img[valid_times, 700 - valid_units] = 1
    
    return img

class SSCDataset(torch.utils.data.Dataset):
    """
    SSCæ•°æ®é›†ç±»
    å¤„ç†HDF5æ ¼å¼çš„è„‰å†²æ•°æ®å¹¶è½¬æ¢ä¸ºSpikingJellyæ ¼å¼
    """
    
    def __init__(self, h5_file_path, max_samples=8000):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        å‚æ•°:
            h5_file_path: HDF5æ–‡ä»¶è·¯å¾„
            max_samples: æœ€å¤§æ ·æœ¬æ•°é‡
        """
        self.h5_file_path = h5_file_path
        
        print(f"ğŸ“ é¢„åŠ è½½SSCæ•°æ®: {h5_file_path}")
        
        with tables.open_file(h5_file_path, mode='r') as f:
            total_samples = len(f.root.labels)
            self.indices = list(range(min(max_samples, total_samples)))
            
            print(f"   æ€»æ ·æœ¬æ•°: {total_samples}, ä½¿ç”¨: {len(self.indices)}")
            
            # é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜ä»¥æé«˜è®­ç»ƒé€Ÿåº¦
            self.data = []
            self.labels = []
            
            for i, idx in enumerate(self.indices):
                if i % 2000 == 0:
                    print(f"   é¢„åŠ è½½è¿›åº¦: {i+1}/{len(self.indices)}")
                
                times = f.root.spikes.times[idx]
                units = f.root.spikes.units[idx]
                label = f.root.labels[idx]
                
                # è½¬æ¢ä¸ºå¯†é›†è¡¨ç¤º
                img = binary_image_readout_fast(times, units, dt=1e-3)
                
                self.data.append(img)
                self.labels.append(label)
            
            print(f"   é¢„åŠ è½½å®Œæˆ: {len(self.data)} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        """
        è·å–å•ä¸ªæ ·æœ¬
        
        è¿”å›:
            data: å½¢çŠ¶ä¸º[æ—¶é—´æ­¥, 1, ç¥ç»å…ƒæ•°]çš„è„‰å†²å¼ é‡
            label: ç±»åˆ«æ ‡ç­¾
        """
        # SpikingJellyæœŸæœ›çš„æ ¼å¼: [T, N] -> [T, 1, N]
        data = torch.FloatTensor(self.data[idx]).unsqueeze(1)  # [1000, 1, 700]
        label = torch.LongTensor([self.labels[idx]]).squeeze()
        return data, label

# ==================== æ¨¡å‹å®šä¹‰ ====================

class VanillaSNN(nn.Module):
    """
    æ™®é€šè„‰å†²ç¥ç»ç½‘ç»œæ¨¡å‹
    ç”¨ä½œåŸºçº¿å¯¹æ¯”
    """
    
    def __init__(self, input_size=700, hidden_size=200, output_size=35):
        """
        åˆå§‹åŒ–æ™®é€šSNNæ¨¡å‹
        
        å‚æ•°:
            input_size: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_size: éšè—å±‚ç»´åº¦
            output_size: è¾“å‡ºç±»åˆ«æ•°
        """
        super(VanillaSNN, self).__init__()
        
        print(f"ğŸ—ï¸  åˆ›å»ºæ™®é€šSNNæ¨¡å‹:")
        print(f"   è¾“å…¥ç»´åº¦: {input_size}")
        print(f"   éšè—ç»´åº¦: {hidden_size}")
        print(f"   è¾“å‡ºç»´åº¦: {output_size}")
        
        # ç¬¬ä¸€å±‚ï¼šçº¿æ€§å±‚ + LIFç¥ç»å…ƒ
        self.fc1 = layer.Linear(input_size, hidden_size)
        self.lif1 = neuron.LIFNode(
            tau=2.0,  # å›ºå®šæ—¶é—´å¸¸æ•°
            surrogate_function=surrogate.ATan(),
            detach_reset=True
        )
        
        # ç¬¬äºŒå±‚ï¼šçº¿æ€§å±‚ + LIFç¥ç»å…ƒ  
        self.fc2 = layer.Linear(hidden_size, output_size)
        self.lif2 = neuron.LIFNode(
            tau=2.0,
            surrogate_function=surrogate.ATan(),
            detach_reset=True
        )
        
        print("âœ… æ™®é€šSNNæ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        å‚æ•°:
            x: è¾“å…¥è„‰å†²åºåˆ—ï¼Œå½¢çŠ¶ä¸º[æ—¶é—´æ­¥, æ‰¹æ¬¡, ç‰¹å¾]
            
        è¿”å›:
            output: è¾“å‡ºlogitsï¼Œå½¢çŠ¶ä¸º[æ‰¹æ¬¡, ç±»åˆ«æ•°]
        """
        # x å½¢çŠ¶: [T, N, input_size]
        T, N = x.shape[0], x.shape[1]
        
        # é‡ç½®ç¥ç»å…ƒçŠ¶æ€
        functional.reset_net(self)
        
        outputs = []
        for t in range(T):
            x_t = x[t]  # [N, input_size]
            
            # ç¬¬ä¸€å±‚å¤„ç†
            h1 = self.fc1(x_t)
            s1 = self.lif1(h1)
            
            # ç¬¬äºŒå±‚å¤„ç†
            h2 = self.fc2(s1)
            s2 = self.lif2(h2)
            
            outputs.append(s2)
        
        # å¯¹æ—¶é—´ç»´åº¦æ±‚å’Œï¼ˆç§¯åˆ†è¯»å‡ºï¼‰
        output = torch.stack(outputs, dim=0).sum(0)  # [N, output_size]
        
        return F.log_softmax(output, dim=1)

class DH_SNN(nn.Module):
    """
    æ ‘çªå¼‚è´¨æ€§è„‰å†²ç¥ç»ç½‘ç»œæ¨¡å‹
    åŸºäºæˆåŠŸçš„å¤šæ—¶é—´å°ºåº¦XORå®ç°
    """
    
    def __init__(self, input_size=700, hidden_size=200, output_size=35, num_branches=2):
        """
        åˆå§‹åŒ–DH-SNNæ¨¡å‹
        
        å‚æ•°:
            input_size: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_size: éšè—å±‚ç»´åº¦  
            output_size: è¾“å‡ºç±»åˆ«æ•°
            num_branches: æ ‘çªåˆ†æ”¯æ•°é‡
        """
        super(DH_SNN, self).__init__()
        
        print(f"ğŸ—ï¸  åˆ›å»ºDH-SNNæ¨¡å‹:")
        print(f"   è¾“å…¥ç»´åº¦: {input_size}")
        print(f"   éšè—ç»´åº¦: {hidden_size}")
        print(f"   è¾“å‡ºç»´åº¦: {output_size}")
        print(f"   åˆ†æ”¯æ•°é‡: {num_branches}")
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.num_branches = num_branches
        
        # åˆ†æ”¯çº¿æ€§å±‚ - æ¯ä¸ªåˆ†æ”¯å¤„ç†è¾“å…¥çš„ä¸€éƒ¨åˆ†
        self.branch1_layer = layer.Linear(input_size // 2, hidden_size, bias=False)
        self.branch2_layer = layer.Linear(input_size // 2, hidden_size, bias=False)
        
        # å¯å­¦ä¹ çš„æ—¶é—´å¸¸æ•°å‚æ•°
        # tau_n: æ ‘çªæ—¶é—´å¸¸æ•°ï¼Œä½¿ç”¨Largeåˆå§‹åŒ–ï¼ˆ2,6ï¼‰
        self.tau_n = nn.Parameter(torch.empty(num_branches, hidden_size).uniform_(2, 6))
        # tau_m: è†œç”µä½æ—¶é—´å¸¸æ•°ï¼Œä½¿ç”¨Mediumåˆå§‹åŒ–ï¼ˆ0,4ï¼‰
        self.tau_m = nn.Parameter(torch.empty(hidden_size).uniform_(0, 4))
        
        # è¾“å‡ºå±‚
        self.output_layer = layer.Linear(hidden_size, output_size)
        
        # ç¥ç»å…ƒçŠ¶æ€å˜é‡
        self.dendritic_current1 = None
        self.dendritic_current2 = None
        self.membrane_potential = None
        self.spike_output = None
        
        print("âœ… DH-SNNæ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    def reset_states(self, batch_size):
        """
        é‡ç½®ç¥ç»å…ƒçŠ¶æ€
        
        å‚æ•°:
            batch_size: æ‰¹æ¬¡å¤§å°
        """
        self.dendritic_current1 = torch.zeros(batch_size, self.hidden_size).to(DEVICE)
        self.dendritic_current2 = torch.zeros(batch_size, self.hidden_size).to(DEVICE)
        self.membrane_potential = torch.rand(batch_size, self.hidden_size).to(DEVICE)
        self.spike_output = torch.zeros(batch_size, self.hidden_size).to(DEVICE)
    
    def surrogate_gradient(self, x):
        """ä»£ç†æ¢¯åº¦å‡½æ•°"""
        return SurrogateGradient.apply(x)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        
        å‚æ•°:
            x: è¾“å…¥è„‰å†²åºåˆ—ï¼Œå½¢çŠ¶ä¸º[æ—¶é—´æ­¥, æ‰¹æ¬¡, ç‰¹å¾]
            
        è¿”å›:
            output: è¾“å‡ºlogitsï¼Œå½¢çŠ¶ä¸º[æ‰¹æ¬¡, ç±»åˆ«æ•°]
        """
        # x å½¢çŠ¶: [T, N, input_size]
        T, N = x.shape[0], x.shape[1]
        
        # åˆå§‹åŒ–ç¥ç»å…ƒçŠ¶æ€
        self.reset_states(N)
        
        outputs = []
        for t in range(T):
            x_t = x[t]  # [N, input_size]
            
            # åˆ†å‰²è¾“å…¥ï¼šå‰åŠéƒ¨åˆ†ç»™åˆ†æ”¯1ï¼ŒååŠéƒ¨åˆ†ç»™åˆ†æ”¯2
            input1 = x_t[:, :self.input_size//2]
            input2 = x_t[:, self.input_size//2:]
            
            # åˆ†æ”¯çº¿æ€§å˜æ¢
            branch1_input = self.branch1_layer(input1)
            branch2_input = self.branch2_layer(input2)
            
            # æ›´æ–°æ ‘çªç”µæµ - ä½¿ç”¨ä¸åŒçš„æ—¶é—´å¸¸æ•°
            beta1 = torch.sigmoid(self.tau_n[0])  # åˆ†æ”¯1æ—¶é—´å¸¸æ•°
            beta2 = torch.sigmoid(self.tau_n[1])  # åˆ†æ”¯2æ—¶é—´å¸¸æ•°
            
            self.dendritic_current1 = beta1 * self.dendritic_current1 + (1 - beta1) * branch1_input
            self.dendritic_current2 = beta2 * self.dendritic_current2 + (1 - beta2) * branch2_input
            
            # æ±‡æ€»æ ‘çªç”µæµ
            total_current = self.dendritic_current1 + self.dendritic_current2
            
            # æ›´æ–°è†œç”µä½ - LIFåŠ¨åŠ›å­¦
            alpha = torch.sigmoid(self.tau_m)
            R_m = 1.0  # è†œé˜»æŠ—
            v_th = 1.0  # è„‰å†²é˜ˆå€¼
            
            self.membrane_potential = (alpha * self.membrane_potential + 
                                     (1 - alpha) * R_m * total_current - 
                                     v_th * self.spike_output)
            
            # ç”Ÿæˆè„‰å†²
            inputs_ = self.membrane_potential - v_th
            self.spike_output = self.surrogate_gradient(inputs_)
            
            outputs.append(self.spike_output)
        
        # å¯¹æ—¶é—´ç»´åº¦æ±‚å’Œï¼ˆç§¯åˆ†è¯»å‡ºï¼‰
        output = torch.stack(outputs, dim=0).sum(0)  # [N, hidden_size]
        
        # è¾“å‡ºå±‚
        final_output = self.output_layer(output)
        
        return F.log_softmax(final_output, dim=1)

class SurrogateGradient(torch.autograd.Function):
    """
    ä»£ç†æ¢¯åº¦å‡½æ•°
    ç”¨äºè„‰å†²å‡½æ•°çš„åå‘ä¼ æ’­
    """
    
    @staticmethod
    def forward(ctx, input):
        """å‰å‘ä¼ æ’­ï¼šé˜¶è·ƒå‡½æ•°"""
        ctx.save_for_backward(input)
        return input.gt(0).float()
    
    @staticmethod
    def backward(ctx, grad_output):
        """åå‘ä¼ æ’­ï¼šé«˜æ–¯è¿‘ä¼¼æ¢¯åº¦"""
        input, = ctx.saved_tensors
        grad_input = grad_output.clone()
        
        # ç®€åŒ–çš„ä»£ç†æ¢¯åº¦
        lens = 0.5
        gamma = 0.5
        temp = torch.exp(-(input**2)/(2*lens**2))/torch.sqrt(2*torch.tensor(torch.pi))/lens
        return grad_input * temp.float() * gamma

# ==================== æ•°æ®å‡†å¤‡ ====================

def prepare_data():
    """
    å‡†å¤‡SSCæ•°æ®é›†
    
    è¿”å›:
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
    """
    print("ğŸ“Š å‡†å¤‡SSCæ•°æ®é›†...")
    
    # åŸå§‹æ•°æ®è·¯å¾„
    data_path = Path("datasets/ssc/data")
    
    # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
    os.makedirs(TEMP_DIR, exist_ok=True)
    
    # è§£å‹HDF5æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    train_h5_temp = Path(TEMP_DIR) / "ssc_train.h5"
    test_h5_temp = Path(TEMP_DIR) / "ssc_test.h5"
    
    if not train_h5_temp.exists():
        print("   è§£å‹è®­ç»ƒæ•°æ®...")
        if (data_path / "ssc_train.h5.gz").exists():
            os.system(f"gunzip -c {data_path}/ssc_train.h5.gz > {train_h5_temp}")
        else:
            print("   âš ï¸  è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return create_mock_data()
    
    if not test_h5_temp.exists():
        print("   è§£å‹æµ‹è¯•æ•°æ®...")
        if (data_path / "ssc_test.h5.gz").exists():
            os.system(f"gunzip -c {data_path}/ssc_test.h5.gz > {test_h5_temp}")
        else:
            print("   âš ï¸  æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return create_mock_data()
    
    # åˆ›å»ºæ•°æ®é›†
    print("   åˆ›å»ºè®­ç»ƒæ•°æ®é›†...")
    train_dataset = SSCDataset(str(train_h5_temp), max_samples=15000)
    print("   åˆ›å»ºæµ‹è¯•æ•°æ®é›†...")
    test_dataset = SSCDataset(str(test_h5_temp), max_samples=5000)
    
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
        num_workers=2, pin_memory=True
    )
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=BATCH_SIZE, shuffle=False,
        num_workers=2, pin_memory=True
    )
    
    return train_loader, test_loader

def create_mock_data():
    """åˆ›å»ºæ¨¡æ‹ŸSSCæ•°æ®ç”¨äºæµ‹è¯•"""
    print("ğŸ² åˆ›å»ºæ¨¡æ‹ŸSSCæ•°æ®...")
    
    # æ¨¡æ‹Ÿæ•°æ®å‚æ•°
    num_train = 8000
    num_test = 2000
    seq_len = 1000
    num_features = 700
    num_classes = 35
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    train_data = torch.zeros(num_train, seq_len, num_features)
    train_labels = torch.randint(0, num_classes, (num_train,))
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®  
    test_data = torch.zeros(num_test, seq_len, num_features)
    test_labels = torch.randint(0, num_classes, (num_test,))
    
    # ä¸ºæ¯ä¸ªæ ·æœ¬æ·»åŠ éšæœºè„‰å†²
    for i in range(num_train):
        num_spikes = torch.randint(100, 500, (1,)).item()
        spike_times = torch.randint(0, seq_len, (num_spikes,))
        spike_features = torch.randint(0, num_features, (num_spikes,))
        for t, f in zip(spike_times, spike_features):
            train_data[i, t, f] = 1.0
    
    for i in range(num_test):
        num_spikes = torch.randint(100, 500, (1,)).item()
        spike_times = torch.randint(0, seq_len, (num_spikes,))
        spike_features = torch.randint(0, num_features, (num_spikes,))
        for t, f in zip(spike_times, spike_features):
            test_data[i, t, f] = 1.0
    
    # æ·»åŠ batchç»´åº¦
    train_data = train_data.unsqueeze(2)  # [N, T, 1, F]
    test_data = test_data.unsqueeze(2)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels)
    test_dataset = torch.utils.data.TensorDataset(test_data, test_labels)
    
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=BATCH_SIZE, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=BATCH_SIZE, shuffle=False
    )
    
    print(f"   æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®: {train_data.shape}")
    print(f"   æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®: {test_data.shape}")
    
    return train_loader, test_loader

# ==================== è®­ç»ƒå’Œæµ‹è¯• ====================

def test_model(model, test_loader):
    """
    æµ‹è¯•æ¨¡å‹æ€§èƒ½
    
    å‚æ•°:
        model: å¾…æµ‹è¯•çš„æ¨¡å‹
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        
    è¿”å›:
        accuracy: æµ‹è¯•å‡†ç¡®ç‡
    """
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            # è°ƒæ•´æ•°æ®ç»´åº¦ï¼š[N, T, 1, F] -> [T, N, F]
            data = data.squeeze(2).transpose(0, 1)
            
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    
    return correct / total

def train_model(model, train_loader, test_loader, epochs, model_name):
    """
    è®­ç»ƒæ¨¡å‹
    
    å‚æ•°:
        model: å¾…è®­ç»ƒçš„æ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        epochs: è®­ç»ƒè½®æ•°
        model_name: æ¨¡å‹åç§°
        
    è¿”å›:
        best_acc: æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡
    """
    
    criterion = nn.CrossEntropyLoss()
    model.to(DEVICE)
    
    # é…ç½®ä¼˜åŒ–å™¨
    if isinstance(model, DH_SNN):
        # DH-SNNä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡
        base_params = [
            model.output_layer.weight,
            model.output_layer.bias,
            model.branch1_layer.weight,
            model.branch2_layer.weight,
        ]
        
        optimizer = torch.optim.Adam([
            {'params': base_params, 'lr': LEARNING_RATE},
            {'params': model.tau_n, 'lr': LEARNING_RATE},
            {'params': model.tau_m, 'lr': LEARNING_RATE},
        ])
    else:
        # æ™®é€šSNNä½¿ç”¨æ ‡å‡†ä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)
    
    best_acc = 0
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {model_name}")
    print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print("-" * 50)
    
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        correct = 0
        total = 0
        
        epoch_start = time.time()
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(DEVICE), target.to(DEVICE)
            # è°ƒæ•´æ•°æ®ç»´åº¦ï¼š[N, T, 1, F] -> [T, N, F]
            data = data.squeeze(2).transpose(0, 1)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), 20)
            
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
        
        scheduler.step()
        
        train_acc = correct / total
        test_acc = test_model(model, test_loader)
        epoch_time = time.time() - epoch_start
        
        if test_acc > best_acc and train_acc > 0.5:
            best_acc = test_acc
        
        print(f'è½®æ¬¡ {epoch:3d}: è®­ç»ƒæŸå¤±={train_loss/len(train_loader):.4f}, '
              f'è®­ç»ƒå‡†ç¡®ç‡={train_acc:.4f}, æµ‹è¯•å‡†ç¡®ç‡={test_acc:.4f}, '
              f'æœ€ä½³={best_acc:.4f}, ç”¨æ—¶={epoch_time:.1f}s')
        
        # æ—©åœæ¡ä»¶
        if "æ™®é€š" in model_name and best_acc > 0.70:
            print(f"âœ… {model_name}è¾¾åˆ°70%ä»¥ä¸Šï¼Œæå‰åœæ­¢è®­ç»ƒ")
            break
        elif "DH-SNN" in model_name and best_acc > 0.80:
            print(f"âœ… {model_name}è¾¾åˆ°80%ä»¥ä¸Šï¼Œæå‰åœæ­¢è®­ç»ƒ")
            break
    
    return best_acc

# ==================== ä¸»å®éªŒå‡½æ•° ====================

def run_ssc_experiment():
    """è¿è¡ŒSSCå®éªŒ"""
    
    print("=" * 80)
    print("ğŸ¤ DH-SNN SSCè„‰å†²è¯­éŸ³å‘½ä»¤è¯†åˆ«å®éªŒ")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    setup_seed(42)
    
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    print(f"ğŸ“ ä¸´æ—¶æ•°æ®è·¯å¾„: {TEMP_DIR}")
    
    try:
        # å‡†å¤‡æ•°æ®
        train_loader, test_loader = prepare_data()
        
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"   æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
        
        # å®éªŒé…ç½®
        experiments = [
            ("æ™®é€šSNN", VanillaSNN),
            ("DH-SNN", DH_SNN),
        ]
        
        results = {}
        start_time = time.time()
        
        # ä¾æ¬¡è®­ç»ƒå„æ¨¡å‹
        for exp_name, model_class in experiments:
            print(f"\nğŸ”¬ å®éªŒ: {exp_name}")
            print("=" * 50)
            
            model = model_class()
            best_acc = train_model(model, train_loader, test_loader, NUM_EPOCHS, exp_name)
            results[exp_name] = best_acc * 100
            
            print(f"âœ… {exp_name} æœ€ä½³å‡†ç¡®ç‡: {best_acc*100:.1f}%")
        
        # ç»“æœæ€»ç»“
        total_time = time.time() - start_time
        print(f"\nğŸ‰ SSCå®éªŒå®Œæˆ! æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
        print("=" * 60)
        print("ğŸ“Š SSCå®éªŒç»“æœ:")
        print("=" * 60)
        
        vanilla_acc = results.get("æ™®é€šSNN", 0)
        dh_acc = results.get("DH-SNN", 0)
        improvement = dh_acc - vanilla_acc
        
        print(f"æ™®é€šSNN:     {vanilla_acc:.1f}%")
        print(f"DH-SNN:      {dh_acc:.1f}%")
        print(f"æ€§èƒ½æå‡:    {improvement:+.1f} ä¸ªç™¾åˆ†ç‚¹")
        
        # ä¸è®ºæ–‡ç»“æœå¯¹æ¯”
        print(f"\nğŸ“ˆ ä¸è®ºæ–‡ç»“æœå¯¹æ¯”:")
        print(f"è®ºæ–‡æ™®é€šSNN:   ~70%")
        print(f"è®ºæ–‡DH-SNN:    ~80%")
        
        if improvement > 5:
            print("ğŸ‰ DH-SNNæ˜¾è‘—ä¼˜äºæ™®é€šSNN!")
        elif improvement > 0:
            print("âœ… DH-SNNä¼˜äºæ™®é€šSNN")
        else:
            print("âš ï¸  ç»“æœéœ€è¦è¿›ä¸€æ­¥åˆ†æ")
        
        # ä¿å­˜ç»“æœ
        results_path = Path("results/ssc_experiment_results.json")
        results_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(results_path, 'w', encoding='utf-8') as f:
            json_results = {
                'experiment_info': {
                    'name': 'SSCè„‰å†²è¯­éŸ³å‘½ä»¤è¯†åˆ«å®éªŒ',
                    'framework': 'SpikingJelly + DH-SNN',
                    'date': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'device': str(DEVICE)
                },
                'results': {
                    'vanilla_snn': {
                        'accuracy': vanilla_acc
                    },
                    'dh_snn': {
                        'accuracy': dh_acc
                    },
                    'improvement': improvement
                }
            }
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    results = run_ssc_experiment()
    if results:
        print(f"\nğŸ SSCå®éªŒæˆåŠŸå®Œæˆ!")
    else:
        print(f"\nâŒ SSCå®éªŒå¤±è´¥")