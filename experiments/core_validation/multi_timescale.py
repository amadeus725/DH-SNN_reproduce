#!/usr/bin/env python3
"""
Multi-Timescale XOR Experiment for DH-SNN Ultimate
å¤šæ—¶é—´å°ºåº¦XORå®éªŒ - éªŒè¯DH-SNNå¤„ç†å¤šæ—¶é—´å°ºåº¦ä¿¡æ¯çš„èƒ½åŠ›

This experiment validates the core innovation of DH-SNN:
- Multiple dendritic branches with different time constants
- Processing information at different temporal scales
- Long-term memory vs. fast response capabilities

Corresponds to Figure 4 in the original paper.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import os
import json
from typing import Dict, List, Tuple, Optional
from datetime import datetime

class MultiTimescaleXORGenerator:
    """
    Multi-timescale XOR data generator
    å¤šæ—¶é—´å°ºåº¦XORæ•°æ®ç”Ÿæˆå™¨
    
    æŒ‰ç…§è®ºæ–‡Figure 4aç²¾ç¡®å®ç°:
    - Signal 1: ä½é¢‘é•¿æœŸä¿¡å· (éœ€è¦é•¿æœŸè®°å¿†)
    - Signal 2: é«˜é¢‘çŸ­æœŸä¿¡å·åºåˆ— (éœ€è¦å¿«é€Ÿå“åº”)  
    - Task: è®°ä½Signal 1å¹¶ä¸æ¯ä¸ªSignal 2è¿›è¡ŒXORè¿ç®—
    """
    
    def __init__(self, device='cpu'):
        self.device = device
        self.total_time = 600
        self.input_size = 40  # 20 for Signal 1, 20 for Signal 2
        
        # æ—¶åºå‚æ•°
        self.signal1_duration = 100  # Signal 1æŒç»­æ—¶é—´
        self.signal2_duration = 30   # æ¯ä¸ªSignal 2æŒç»­æ—¶é—´
        self.signal2_interval = 80   # Signal 2ä¹‹é—´çš„é—´éš”
        self.response_window = 20    # å“åº”çª—å£
        
        # å‘æ”¾ç‡è®¾ç½® - åˆ›å»ºæœ‰æŒ‘æˆ˜æ€§çš„æ—¶é—´å°ºåº¦å·®å¼‚
        self.low_rate = 0.05   # ä½å‘æ”¾ç‡æ¨¡å¼
        self.high_rate = 0.25  # é«˜å‘æ”¾ç‡æ¨¡å¼
        self.noise_rate = 0.01 # èƒŒæ™¯å™ªå£°
        
    def generate_sample(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """ç”Ÿæˆå•ä¸ªå¤šæ—¶é—´å°ºåº¦XORæ ·æœ¬"""
        input_data = torch.zeros(self.total_time, self.input_size)
        target_data = torch.zeros(self.total_time, 1)
        
        # æ·»åŠ èƒŒæ™¯å™ªå£°å¢åŠ ä»»åŠ¡éš¾åº¦
        noise_mask = torch.rand(self.total_time, self.input_size) < self.noise_rate
        input_data[noise_mask] = 1.0
        
        # Signal 1: ä½é¢‘é•¿æœŸä¿¡å· (æ—¶é—´æ­¥ 50-150)
        # è¿™ä¸ªä¿¡å·éœ€è¦è¢«é•¿æœŸè®°ä½ï¼Œç”¨äºä¸åç»­çš„Signal 2è¿›è¡ŒXOR
        signal1_start = 50
        signal1_end = signal1_start + self.signal1_duration
        signal1_type = np.random.choice([0, 1])  # 0=ä½å‘æ”¾ç‡, 1=é«˜å‘æ”¾ç‡
        
        if signal1_type == 1:
            signal1_mask = torch.rand(self.signal1_duration, 20) < self.high_rate
        else:
            signal1_mask = torch.rand(self.signal1_duration, 20) < self.low_rate
            
        input_data[signal1_start:signal1_end, :20] = signal1_mask.float()
        
        # Signal 2åºåˆ—: é«˜é¢‘çŸ­æœŸä¿¡å·ï¼Œéœ€è¦å¿«é€Ÿå“åº”
        signal2_starts = [200, 280, 360, 440, 520]  # 5ä¸ªSignal 2
        
        for i, start_time in enumerate(signal2_starts):
            if start_time + self.signal2_duration >= self.total_time:
                break
                
            signal2_type = np.random.choice([0, 1])
            
            if signal2_type == 1:
                signal2_mask = torch.rand(self.signal2_duration, 20) < self.high_rate
            else:
                signal2_mask = torch.rand(self.signal2_duration, 20) < self.low_rate
                
            input_data[start_time:start_time+self.signal2_duration, 20:] = signal2_mask.float()
            
            # XORç›®æ ‡: Signal 1 XOR Signal 2
            xor_result = signal1_type ^ signal2_type
            response_start = start_time + self.signal2_duration
            response_end = min(response_start + self.response_window, self.total_time)
            
            target_data[response_start:response_end, 0] = float(xor_result)
            
        return input_data.to(self.device), target_data.to(self.device)
    
    def generate_dataset(self, num_samples: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """ç”Ÿæˆæ•°æ®é›†"""
        inputs, targets = [], []
        
        for _ in range(num_samples):
            input_data, target_data = self.generate_sample()
            inputs.append(input_data)
            targets.append(target_data)
            
        return torch.stack(inputs), torch.stack(targets)

class VanillaSFNN(nn.Module):
    """
    Vanilla Spiking Feed-forward Neural Network
    ä¼ ç»ŸSFNNä½œä¸ºåŸºçº¿æ¨¡å‹
    """
    
    def __init__(self, input_size=40, hidden_size=64, output_size=1):
        super().__init__()
        self.dense = nn.Linear(input_size, hidden_size)
        self.output = nn.Linear(hidden_size, output_size)
        
        # å›ºå®šçš„ä¸­ç­‰æ—¶é—´å¸¸æ•°
        self.tau = nn.Parameter(torch.ones(hidden_size) * 2.0)
        self.register_buffer('mem', torch.zeros(1, hidden_size))
        
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        self.mem = torch.zeros(batch_size, self.mem.size(1)).to(x.device)
        outputs = []
        
        for t in range(seq_len):
            input_current = self.dense(x[:, t, :])
            alpha = torch.sigmoid(self.tau)
            self.mem = alpha * self.mem + (1 - alpha) * input_current
            output = torch.sigmoid(self.output(self.mem))
            outputs.append(output)
            
        return torch.stack(outputs, dim=1)

class OneBranchDH_SFNN(nn.Module):
    """
    Single-branch DH-SFNN
    å•åˆ†æ”¯DH-SFNNï¼Œå…·æœ‰å¯å­¦ä¹ çš„æ ‘çªæ—¶é—´å¸¸æ•°
    """
    
    def __init__(self, input_size=40, hidden_size=64, output_size=1, tau_init='medium'):
        super().__init__()
        self.dense = nn.Linear(input_size, hidden_size)
        self.output = nn.Linear(hidden_size, output_size)
        
        # è†œç”µä½å’Œæ ‘çªæ—¶é—´å¸¸æ•°
        self.tau_m = nn.Parameter(torch.ones(hidden_size) * 2.0)
        self.tau_n = nn.Parameter(torch.ones(hidden_size) * 2.0)
        
        # æ ¹æ®åˆå§‹åŒ–ç­–ç•¥è®¾ç½®æ—¶é—´å¸¸æ•°
        if tau_init == 'small':
            nn.init.uniform_(self.tau_n, -2.0, 0.0)  # å¿«é€Ÿå“åº”
        elif tau_init == 'large':
            nn.init.uniform_(self.tau_n, 2.0, 4.0)   # é•¿æœŸè®°å¿†
        else:  # medium
            nn.init.uniform_(self.tau_n, 0.0, 2.0)   # ä¸­ç­‰
            
        self.register_buffer('mem', torch.zeros(1, hidden_size))
        self.register_buffer('d_current', torch.zeros(1, hidden_size))
        
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        self.mem = torch.zeros(batch_size, self.mem.size(1)).to(x.device)
        self.d_current = torch.zeros(batch_size, self.d_current.size(1)).to(x.device)
        outputs = []
        
        for t in range(seq_len):
            # æ ‘çªç”µæµæ›´æ–°
            d_input = self.dense(x[:, t, :])
            beta = torch.sigmoid(self.tau_n)
            self.d_current = beta * self.d_current + (1 - beta) * d_input
            
            # è†œç”µä½æ›´æ–°
            alpha = torch.sigmoid(self.tau_m)
            self.mem = alpha * self.mem + (1 - alpha) * self.d_current
            
            output = torch.sigmoid(self.output(self.mem))
            outputs.append(output)
            
        return torch.stack(outputs, dim=1)

class TwoBranchDH_SFNN(nn.Module):
    """
    Two-branch DH-SFNN - The core innovation
    åŒåˆ†æ”¯DH-SFNN - æ ¸å¿ƒåˆ›æ–°æ¨¡å‹
    
    Key features:
    - Branch 1: Long-term memory (large time constant) for Signal 1
    - Branch 2: Fast response (small time constant) for Signal 2  
    - Automatic temporal specialization through learning
    """
    
    def __init__(self, input_size=40, hidden_size=64, output_size=1, 
                 beneficial_init=True, learnable=True):
        super().__init__()
        
        # ä¸“é—¨çš„åˆ†æ”¯è¿æ¥
        self.branch1_dense = nn.Linear(input_size//2, hidden_size)  # Signal 1 branch
        self.branch2_dense = nn.Linear(input_size//2, hidden_size)  # Signal 2 branch
        self.output = nn.Linear(hidden_size, output_size)
        
        # è†œç”µä½æ—¶é—´å¸¸æ•° (Mediumåˆå§‹åŒ–)
        self.tau_m = nn.Parameter(torch.zeros(hidden_size))
        nn.init.uniform_(self.tau_m, 0.0, 4.0)
        
        # æ ‘çªæ—¶é—´å¸¸æ•°
        self.tau_n_branch1 = nn.Parameter(torch.zeros(hidden_size))
        self.tau_n_branch2 = nn.Parameter(torch.zeros(hidden_size))
        
        # æœ‰ç›Šåˆå§‹åŒ– vs éšæœºåˆå§‹åŒ–
        if beneficial_init:
            # Branch 1: Large initialization U(2,6) - é•¿æœŸè®°å¿†
            nn.init.uniform_(self.tau_n_branch1, 2.0, 6.0)
            # Branch 2: Small initialization U(-4,0) - å¿«é€Ÿå“åº”
            nn.init.uniform_(self.tau_n_branch2, -4.0, 0.0)
        else:
            # éšæœºåˆå§‹åŒ– - Medium U(0,4)
            nn.init.uniform_(self.tau_n_branch1, 0.0, 4.0)
            nn.init.uniform_(self.tau_n_branch2, 0.0, 4.0)
            
        # æ§åˆ¶æ˜¯å¦å¯å­¦ä¹ 
        self.tau_m.requires_grad = learnable
        self.tau_n_branch1.requires_grad = learnable
        self.tau_n_branch2.requires_grad = learnable
        
        # ç¥ç»å…ƒçŠ¶æ€
        self.register_buffer('mem', torch.zeros(1, hidden_size))
        self.register_buffer('d1_current', torch.zeros(1, hidden_size))
        self.register_buffer('d2_current', torch.zeros(1, hidden_size))
        
        # è®°å½•åˆ†æ”¯æ´»åŠ¨ç”¨äºåˆ†æ
        self.branch1_activities = []
        self.branch2_activities = []
        
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        
        # é‡ç½®çŠ¶æ€
        self.mem = torch.zeros(batch_size, self.mem.size(1)).to(x.device)
        self.d1_current = torch.zeros(batch_size, self.d1_current.size(1)).to(x.device)
        self.d2_current = torch.zeros(batch_size, self.d2_current.size(1)).to(x.device)
        
        outputs = []
        self.branch1_activities = []
        self.branch2_activities = []
        
        for t in range(seq_len):
            # åˆ†ç¦»è¾“å…¥åˆ°ä¸“é—¨çš„åˆ†æ”¯
            branch1_input = x[:, t, :20]  # Signal 1 (é•¿æœŸè®°å¿†éœ€æ±‚)
            branch2_input = x[:, t, 20:]  # Signal 2 (å¿«é€Ÿå“åº”éœ€æ±‚)
            
            # Branch 1: é•¿æœŸè®°å¿†åˆ†æ”¯
            d1_in = self.branch1_dense(branch1_input)
            beta1 = torch.sigmoid(self.tau_n_branch1)  # å¤§æ—¶é—´å¸¸æ•° -> æ…¢è¡°å‡
            self.d1_current = beta1 * self.d1_current + (1 - beta1) * d1_in
            
            # Branch 2: å¿«é€Ÿå“åº”åˆ†æ”¯
            d2_in = self.branch2_dense(branch2_input)
            beta2 = torch.sigmoid(self.tau_n_branch2)  # å°æ—¶é—´å¸¸æ•° -> å¿«è¡°å‡
            self.d2_current = beta2 * self.d2_current + (1 - beta2) * d2_in
            
            # è®°å½•åˆ†æ”¯æ´»åŠ¨
            self.branch1_activities.append(self.d1_current.clone().detach())
            self.branch2_activities.append(self.d2_current.clone().detach())
            
            # æ•´åˆä¸¤ä¸ªåˆ†æ”¯
            total_dendritic_current = self.d1_current + self.d2_current
            
            # è†œç”µä½æ›´æ–°
            alpha = torch.sigmoid(self.tau_m)
            self.mem = alpha * self.mem + (1 - alpha) * total_dendritic_current
            
            output = torch.sigmoid(self.output(self.mem))
            outputs.append(output)
            
        return torch.stack(outputs, dim=1)
    
    def get_time_constants(self) -> Dict[str, torch.Tensor]:
        """è·å–å½“å‰æ—¶é—´å¸¸æ•°ç”¨äºåˆ†æ"""
        return {
            'tau_m': torch.sigmoid(self.tau_m).detach().cpu(),
            'tau_n_branch1': torch.sigmoid(self.tau_n_branch1).detach().cpu(),
            'tau_n_branch2': torch.sigmoid(self.tau_n_branch2).detach().cpu()
        }
    
    def analyze_specialization(self) -> Dict:
        """åˆ†æåˆ†æ”¯ç‰¹åŒ–ç¨‹åº¦"""
        tau_constants = self.get_time_constants()
        
        branch1_tau = tau_constants['tau_n_branch1'].mean().item()
        branch2_tau = tau_constants['tau_n_branch2'].mean().item()
        
        specialization = {
            'branch1_tau_mean': branch1_tau,
            'branch2_tau_mean': branch2_tau,
            'tau_difference': abs(branch1_tau - branch2_tau),
            'specialization_degree': abs(branch1_tau - branch2_tau) / (branch1_tau + branch2_tau + 1e-8),
            'is_specialized': abs(branch1_tau - branch2_tau) > 0.3
        }
        
        return specialization

class MultiBranchDH_SFNN(nn.Module):
    """
    Multi-branch DH-SFNN for extended experiments
    å¤šåˆ†æ”¯DH-SFNNç”¨äºæ‰©å±•å®éªŒ
    """
    
    def __init__(self, input_size=40, hidden_size=64, output_size=1, num_branches=4):
        super().__init__()
        
        self.num_branches = num_branches
        self.branch_size = hidden_size // num_branches
        
        # å¤šä¸ªåˆ†æ”¯
        self.branches = nn.ModuleList([
            nn.Linear(input_size, self.branch_size) 
            for _ in range(num_branches)
        ])
        
        self.output = nn.Linear(hidden_size, output_size)
        
        # æ¯ä¸ªåˆ†æ”¯çš„æ—¶é—´å¸¸æ•°
        self.tau_m = nn.Parameter(torch.zeros(hidden_size))
        self.tau_n_branches = nn.ParameterList([
            nn.Parameter(torch.zeros(self.branch_size))
            for _ in range(num_branches)
        ])
        
        # åˆå§‹åŒ–ä¸åŒçš„æ—¶é—´å°ºåº¦
        nn.init.uniform_(self.tau_m, 0.0, 4.0)
        for i, tau_n in enumerate(self.tau_n_branches):
            # åˆ†é…ä¸åŒçš„æ—¶é—´å°ºåº¦èŒƒå›´
            min_val = -4.0 + i * 2.0
            max_val = min_val + 3.0
            nn.init.uniform_(tau_n, min_val, max_val)
            
        # ç¥ç»å…ƒçŠ¶æ€
        self.register_buffer('mem', torch.zeros(1, hidden_size))
        self.register_buffer('d_currents', torch.zeros(1, hidden_size))
        
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        
        self.mem = torch.zeros(batch_size, self.mem.size(1)).to(x.device)
        self.d_currents = torch.zeros(batch_size, self.d_currents.size(1)).to(x.device)
        
        outputs = []
        
        for t in range(seq_len):
            # è®¡ç®—æ¯ä¸ªåˆ†æ”¯çš„è´¡çŒ®
            branch_outputs = []
            
            for i, (branch, tau_n) in enumerate(zip(self.branches, self.tau_n_branches)):
                start_idx = i * self.branch_size
                end_idx = start_idx + self.branch_size
                
                d_in = branch(x[:, t, :])
                beta = torch.sigmoid(tau_n)
                
                self.d_currents[:, start_idx:end_idx] = (
                    beta * self.d_currents[:, start_idx:end_idx] + 
                    (1 - beta) * d_in
                )
            
            # è†œç”µä½æ›´æ–°
            alpha = torch.sigmoid(self.tau_m)
            self.mem = alpha * self.mem + (1 - alpha) * self.d_currents
            
            output = torch.sigmoid(self.output(self.mem))
            outputs.append(output)
            
        return torch.stack(outputs, dim=1)

class MultiTimescaleExperiment:
    """
    Multi-timescale XOR experiment runner
    å¤šæ—¶é—´å°ºåº¦XORå®éªŒè¿è¡Œå™¨
    """
    
    def __init__(self, device='cpu', save_dir='./results'):
        self.device = device
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
    def train_model(self, model: nn.Module, train_data: torch.Tensor, 
                   train_targets: torch.Tensor, test_data: torch.Tensor,
                   test_targets: torch.Tensor, model_name: str, 
                   epochs: int = 80) -> float:
        """è®­ç»ƒæ¨¡å‹å¹¶è¿”å›æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡"""
        
        print(f"ğŸ‹ï¸ è®­ç»ƒ {model_name}")
        model = model.to(self.device)
        
        # ä¼˜åŒ–å™¨è®¾ç½®
        optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)
        criterion = nn.BCELoss()
        
        best_acc = 0.0
        train_history = {'losses': [], 'accuracies': []}
        
        for epoch in range(epochs):
            model.train()
            total_loss = 0
            num_batches = 0
            
            # å°æ‰¹æ¬¡è®­ç»ƒ
            batch_size = 8
            for i in range(0, len(train_data), batch_size):
                batch_data = train_data[i:i+batch_size].to(self.device)
                batch_targets = train_targets[i:i+batch_size].to(self.device)
                
                optimizer.zero_grad()
                outputs = model(batch_data)
                
                # åªåœ¨å“åº”çª—å£è®¡ç®—æŸå¤±
                mask = (batch_targets.sum(dim=-1) > 0).unsqueeze(-1)
                if mask.sum() > 0:
                    masked_outputs = outputs[mask]
                    masked_targets = batch_targets[mask]
                    loss = criterion(masked_outputs, masked_targets)
                    
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                    
                    total_loss += loss.item()
                    num_batches += 1
            
            # æµ‹è¯•è¯„ä¼°
            if epoch % 10 == 0 or epoch == epochs - 1:
                acc = self.evaluate_model(model, test_data, test_targets)
                best_acc = max(best_acc, acc)
                
                avg_loss = total_loss / max(num_batches, 1)
                train_history['losses'].append(avg_loss)
                train_history['accuracies'].append(acc)
                
                print(f"  Epoch {epoch+1:3d}: Loss={avg_loss:.4f}, Acc={acc:.1f}%, Best={best_acc:.1f}%")
        
        return best_acc
    
    def evaluate_model(self, model: nn.Module, test_data: torch.Tensor, 
                      test_targets: torch.Tensor) -> float:
        """è¯„ä¼°æ¨¡å‹å‡†ç¡®ç‡"""
        model.eval()
        with torch.no_grad():
            test_outputs = model(test_data.to(self.device))
            test_targets_device = test_targets.to(self.device)
            
            # åªåœ¨å“åº”çª—å£è¯„ä¼°
            mask = (test_targets_device.sum(dim=-1) > 0).unsqueeze(-1)
            if mask.sum() > 0:
                masked_outputs = test_outputs[mask]
                masked_targets = test_targets_device[mask]
                
                pred = (masked_outputs > 0.5).float()
                acc = (pred == masked_targets).float().mean().item() * 100
                return acc
            return 0.0
    
    def run_branch_comparison_experiment(self, num_trials: int = 5) -> Dict:
        """è¿è¡Œåˆ†æ”¯æ•°é‡å¯¹æ¯”å®éªŒ (Figure 4b)"""
        
        print(f"\nğŸ§ª å¤šæ—¶é—´å°ºåº¦XORå®éªŒ - åˆ†æ”¯å¯¹æ¯”")
        print("="*60)
        
        # ç”Ÿæˆæ•°æ®
        generator = MultiTimescaleXORGenerator(self.device)
        train_data, train_targets = generator.generate_dataset(200)
        test_data, test_targets = generator.generate_dataset(50)
        
        print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ: è®­ç»ƒ{train_data.shape}, æµ‹è¯•{test_data.shape}")
        
        # å®éªŒé…ç½®
        experiments = [
            ("Vanilla SFNN", lambda: VanillaSFNN()),
            ("1-Branch DH-SFNN (Small)", lambda: OneBranchDH_SFNN(tau_init='small')),
            ("1-Branch DH-SFNN (Large)", lambda: OneBranchDH_SFNN(tau_init='large')),
            ("2-Branch DH-SFNN (Beneficial)", lambda: TwoBranchDH_SFNN(beneficial_init=True, learnable=True)),
            ("2-Branch DH-SFNN (Fixed)", lambda: TwoBranchDH_SFNN(beneficial_init=True, learnable=False)),
            ("2-Branch DH-SFNN (Random)", lambda: TwoBranchDH_SFNN(beneficial_init=False, learnable=True)),
            ("4-Branch DH-SFNN", lambda: MultiBranchDH_SFNN(num_branches=4)),
        ]
        
        results = {}
        
        for exp_name, model_creator in experiments:
            print(f"\nğŸ“Š å®éªŒ: {exp_name}")
            print("-" * 50)
            
            trial_results = []
            time_constants_history = []
            
            for trial in range(num_trials):
                print(f"  ğŸ”„ è¯•éªŒ {trial+1}/{num_trials}")
                
                model = model_creator()
                
                # è®°å½•åˆå§‹æ—¶é—´å¸¸æ•°
                if hasattr(model, 'get_time_constants'):
                    initial_tau = model.get_time_constants()
                    print(f"    åˆå§‹Ï„: B1={initial_tau.get('tau_n_branch1', torch.tensor([0])).mean():.3f}, "
                          f"B2={initial_tau.get('tau_n_branch2', torch.tensor([0])).mean():.3f}")
                
                # è®­ç»ƒæ¨¡å‹
                acc = self.train_model(
                    model, train_data, train_targets,
                    test_data, test_targets, f"{exp_name}_trial_{trial+1}"
                )
                
                trial_results.append(acc)
                
                # è®°å½•æœ€ç»ˆæ—¶é—´å¸¸æ•°
                if hasattr(model, 'get_time_constants'):
                    final_tau = model.get_time_constants()
                    time_constants_history.append(final_tau)
                    print(f"    æœ€ç»ˆÏ„: B1={final_tau.get('tau_n_branch1', torch.tensor([0])).mean():.3f}, "
                          f"B2={final_tau.get('tau_n_branch2', torch.tensor([0])).mean():.3f}")
                
                # åˆ†æç‰¹åŒ–ç¨‹åº¦
                if hasattr(model, 'analyze_specialization'):
                    spec = model.analyze_specialization()
                    print(f"    ç‰¹åŒ–åº¦: {spec['specialization_degree']:.3f}, "
                          f"å·²ç‰¹åŒ–: {'âœ…' if spec['is_specialized'] else 'âŒ'}")
            
            # ç»Ÿè®¡ç»“æœ
            mean_acc = np.mean(trial_results)
            std_acc = np.std(trial_results)
            
            results[exp_name] = {
                'mean_accuracy': mean_acc,
                'std_accuracy': std_acc,
                'trial_results': trial_results,
                'time_constants_history': time_constants_history
            }
            
            print(f"  ğŸ“ˆ æœ€ç»ˆç»“æœ: {mean_acc:.1f}% Â± {std_acc:.1f}%")
        
        # ä¿å­˜ç»“æœ
        results_path = os.path.join(self.save_dir, 'multi_timescale_results.json')
        with open(results_path, 'w') as f:
            # Convert tensors to lists for JSON serialization
            json_results = {}
            for exp_name, exp_data in results.items():
                json_results[exp_name] = {
                    'mean_accuracy': exp_data['mean_accuracy'],
                    'std_accuracy': exp_data['std_accuracy'],
                    'trial_results': exp_data['trial_results']
                }
            json.dump(json_results, f, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
        return results
    
    def visualize_results(self, results: Dict) -> None:
        """å¯è§†åŒ–å®éªŒç»“æœ"""
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # æ€§èƒ½å¯¹æ¯”å›¾
        exp_names = list(results.keys())
        means = [results[name]['mean_accuracy'] for name in exp_names]
        stds = [results[name]['std_accuracy'] for name in exp_names]
        
        bars = ax1.bar(range(len(exp_names)), means, yerr=stds, capsize=5)
        ax1.set_xlabel('Model Architecture')
        ax1.set_ylabel('Accuracy (%)')
        ax1.set_title('Multi-Timescale XOR Performance Comparison')
        ax1.set_xticks(range(len(exp_names)))
        ax1.set_xticklabels(exp_names, rotation=45, ha='right')
        ax1.grid(True, alpha=0.3)
        
        # é¢œè‰²ç¼–ç 
        colors = ['red', 'orange', 'orange', 'green', 'blue', 'purple', 'darkgreen']
        for bar, color in zip(bars, colors[:len(bars)]):
            bar.set_color(color)
            bar.set_alpha(0.7)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (mean, std) in enumerate(zip(means, stds)):
            ax1.text(i, mean + std + 1, f'{mean:.1f}%', 
                    ha='center', va='bottom', fontweight='bold')
        
        # åˆ›æ–°ä¼˜åŠ¿åˆ†æ
        baseline_acc = results.get('Vanilla SFNN', {}).get('mean_accuracy', 0)
        innovations = []
        improvements = []
        
        for name, data in results.items():
            if 'DH-SFNN' in name:
                innovations.append(name.replace('DH-SFNN', 'DH'))
                improvements.append(data['mean_accuracy'] - baseline_acc)
        
        if innovations:
            bars2 = ax2.bar(range(len(innovations)), improvements)
            ax2.set_xlabel('DH-SNN Variant')
            ax2.set_ylabel('Improvement over Vanilla (%)')
            ax2.set_title('Innovation Impact Analysis')
            ax2.set_xticks(range(len(innovations)))
            ax2.set_xticklabels(innovations, rotation=45, ha='right')
            ax2.grid(True, alpha=0.3)
            ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            
            # é¢œè‰²ç¼–ç æ”¹è¿›ç¨‹åº¦
            for bar, improvement in zip(bars2, improvements):
                if improvement > 20:
                    bar.set_color('darkgreen')
                elif improvement > 10:
                    bar.set_color('green')
                elif improvement > 0:
                    bar.set_color('orange')
                else:
                    bar.set_color('red')
                bar.set_alpha(0.7)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                ax2.text(bar.get_x() + bar.get_width()/2, 
                        bar.get_height() + (1 if improvement > 0 else -3),
                        f'+{improvement:.1f}%' if improvement > 0 else f'{improvement:.1f}%',
                        ha='center', va='bottom' if improvement > 0 else 'top',
                        fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        plot_path = os.path.join(self.save_dir, 'multi_timescale_results.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {plot_path}")
    
    def analyze_temporal_specialization(self, results: Dict) -> None:
        """åˆ†ææ—¶é—´ç‰¹åŒ–"""
        
        print(f"\nğŸ”¬ æ—¶é—´ç‰¹åŒ–åˆ†æ")
        print("="*50)
        
        for exp_name, exp_data in results.items():
            if 'time_constants_history' in exp_data and exp_data['time_constants_history']:
                print(f"\nğŸ“Š {exp_name}:")
                
                # åˆ†ææœ€åä¸€æ¬¡è¯•éªŒçš„æ—¶é—´å¸¸æ•°
                final_tau = exp_data['time_constants_history'][-1]
                
                if 'tau_n_branch1' in final_tau and 'tau_n_branch2' in final_tau:
                    tau1_mean = final_tau['tau_n_branch1'].mean().item()
                    tau2_mean = final_tau['tau_n_branch2'].mean().item()
                    tau_diff = abs(tau1_mean - tau2_mean)
                    
                    print(f"  Branch 1 æ—¶é—´å¸¸æ•°: {tau1_mean:.3f}")
                    print(f"  Branch 2 æ—¶é—´å¸¸æ•°: {tau2_mean:.3f}")
                    print(f"  åˆ†æ”¯åˆ†åŒ–ç¨‹åº¦: {tau_diff:.3f}")
                    
                    if tau_diff > 0.3:
                        print(f"  âœ… æˆåŠŸå®ç°æ—¶é—´ç‰¹åŒ–")
                        if tau1_mean > tau2_mean:
                            print(f"     Branch1=é•¿æœŸè®°å¿†, Branch2=å¿«é€Ÿå“åº”")
                        else:
                            print(f"     Branch1=å¿«é€Ÿå“åº”, Branch2=é•¿æœŸè®°å¿†")
                    else:
                        print(f"  âš ï¸ æ—¶é—´ç‰¹åŒ–ç¨‹åº¦è¾ƒä½")

def run_multi_timescale_experiment():
    """è¿è¡Œå®Œæ•´çš„å¤šæ—¶é—´å°ºåº¦å®éªŒ"""
    
    print("ğŸš€ DH-SNN Ultimate: Multi-Timescale XOR Experiment")
    print("="*70)
    print("éªŒè¯DH-SNNå¤„ç†å¤šæ—¶é—´å°ºåº¦ä¿¡æ¯çš„æ ¸å¿ƒåˆ›æ–°èƒ½åŠ›")
    print("Validating DH-SNN's core innovation in multi-timescale processing")
    print("="*70)
    
    # è®¾å¤‡è®¾ç½®
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå®éªŒè¿è¡Œå™¨
    experiment = MultiTimescaleExperiment(device=device)
    
    # è¿è¡Œä¸»å®éªŒ
    results = experiment.run_branch_comparison_experiment(num_trials=3)
    
    # ç»“æœåˆ†æ
    print(f"\nğŸ‰ å®éªŒå®Œæˆ! å¤šæ—¶é—´å°ºåº¦XORç»“æœ:")
    print("="*60)
    
    for exp_name, exp_data in results.items():
        mean_acc = exp_data['mean_accuracy']
        std_acc = exp_data['std_accuracy']
        print(f"{exp_name:35s}: {mean_acc:5.1f}% Â± {std_acc:4.1f}%")
    
    # å¯è§†åŒ–ç»“æœ
    experiment.visualize_results(results)
    
    # åˆ†ææ—¶é—´ç‰¹åŒ–
    experiment.analyze_temporal_specialization(results)
    
    # æ ¸å¿ƒå‘ç°æ€»ç»“
    print(f"\nğŸ’¡ æ ¸å¿ƒå‘ç°:")
    print("-" * 30)
    
    vanilla_acc = results.get('Vanilla SFNN', {}).get('mean_accuracy', 0)
    best_dh_name = max([name for name in results.keys() if 'DH-SFNN' in name], 
                       key=lambda x: results[x]['mean_accuracy'])
    best_dh_acc = results[best_dh_name]['mean_accuracy']
    
    print(f"1. âœ… DH-SNNæ˜¾è‘—ä¼˜äºä¼ ç»ŸSNN:")
    print(f"   æœ€ä½³DH-SNN ({best_dh_name}): {best_dh_acc:.1f}%")
    print(f"   Vanilla SNN: {vanilla_acc:.1f}%")
    print(f"   æ€§èƒ½æå‡: +{best_dh_acc - vanilla_acc:.1f}%")
    
    beneficial_acc = results.get('2-Branch DH-SFNN (Beneficial)', {}).get('mean_accuracy', 0)
    random_acc = results.get('2-Branch DH-SFNN (Random)', {}).get('mean_accuracy', 0)
    
    if beneficial_acc > 0 and random_acc > 0:
        print(f"\n2. âœ… æœ‰ç›Šåˆå§‹åŒ–çš„é‡è¦æ€§:")
        print(f"   æœ‰ç›Šåˆå§‹åŒ–: {beneficial_acc:.1f}%")
        print(f"   éšæœºåˆå§‹åŒ–: {random_acc:.1f}%")
        print(f"   åˆå§‹åŒ–ä¼˜åŠ¿: +{beneficial_acc - random_acc:.1f}%")
    
    fixed_acc = results.get('2-Branch DH-SFNN (Fixed)', {}).get('mean_accuracy', 0)
    learnable_acc = results.get('2-Branch DH-SFNN (Beneficial)', {}).get('mean_accuracy', 0)
    
    if fixed_acc > 0 and learnable_acc > 0:
        print(f"\n3. âœ… å¯å­¦ä¹ æ—¶é—´å¸¸æ•°çš„ä¼˜åŠ¿:")
        print(f"   å¯å­¦ä¹ æ—¶é—´å¸¸æ•°: {learnable_acc:.1f}%")
        print(f"   å›ºå®šæ—¶é—´å¸¸æ•°: {fixed_acc:.1f}%")
        print(f"   å­¦ä¹ ä¼˜åŠ¿: +{learnable_acc - fixed_acc:.1f}%")
    
    print(f"\nğŸ¯ åˆ›æ–°éªŒè¯æˆåŠŸ! DH-SNNåœ¨å¤šæ—¶é—´å°ºåº¦ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„ä¼˜åŠ¿")
    
    return results

if __name__ == '__main__':
    # è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡ç°æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        results = run_multi_timescale_experiment()
        print(f"\nğŸ Multi-Timescaleå®éªŒæˆåŠŸå®Œæˆ!")
    except Exception as e:
        print(f"\nâŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()